{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RFMBuilder_DD_version.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "r31mfkHvpTbz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RFM builder by data driven paradigm\n",
        "__Author:__ Moyocoyani Molina-Esp√≠ritu\n",
        "\n",
        "__Date:__ 27/12/2018\n",
        "\n",
        "Customer segments obtained by an RFM analysis are well defined. There are some specifications for managing 11 segments by [ Anish Nair](https://www.putler.com/rfm-analysis/), or if you prefer fewer segments, you can follow this article written by [Pushpa Makhija](https://clevertap.com/blog/rfm-analysis/).\n",
        "\n",
        "Showing up next we write a code that obtain the 11 segments listed by  [ Anish Nair](https://www.putler.com/rfm-analysis/). Is worthy to mention that we proceed by generate an RFM partition based on quintiles.\n",
        "\n",
        "The main idea is that you use this code with a dataset wherein the _recency_, _frequency_ and _monetary_ (or engagement) variable are well defined. Hence, the code generates the corresponding label for each customer in your dataset.\n",
        "\n",
        "I named this version as data driven paradigm because I work with this approach. Basically I build a cubic space where the different labels are delimited by pre-defined boundaries. Next, a few classificators are trainned, and the best of them is selected. This classificator is in charge for assigning the corresponding labels to each customer on the dataset.\n",
        "\n",
        "We require numpy and pandas libraries."
      ]
    },
    {
      "metadata": {
        "id": "FZM0leTm_XDo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tOr4Hvvg9jWF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creation of the theoretical cubic space (training set)\n",
        "First we need to create a theoretical space with well defined boundaries. We call this space as Local Space, and this is going to be our training dataset.\n",
        "\n",
        "LocalSpace() will generate a cubic space of $NxNxN$ dimensions, wehere $N$ is named as totalCostumers. This is produced by $self.shapeReFactor$ variable."
      ]
    },
    {
      "metadata": {
        "id": "7-4wKmaq9h91",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class LocalSpace():\n",
        "  \n",
        "    def __init__(self,label,totalCostumers,x,y,z):\n",
        "        self._label=label\n",
        "        self._noCostumers = totalCostumers\n",
        "        self._x= x\n",
        "        self._y= y\n",
        "        self._z= z\n",
        "        self.shapeReFactor=totalCostumers*totalCostumers*totalCostumers\n",
        "\n",
        "    def CreateCoordinates(self): #Coordinates correspond to recency, frequency and monetary variables\n",
        "        x_ = np.linspace(self._x[0],self._x[1],self._noCostumers)\n",
        "        y_ = np.linspace(self._y[0],self._y[1],self._noCostumers)\n",
        "        z_ = np.linspace(self._z[0],self._z[1],self._noCostumers)\n",
        "        return(x_,y_,z_)\n",
        "\n",
        "    def CreateGrids4Segment(self):\n",
        "        return np.meshgrid(self.CreateCoordinates()[0],self.CreateCoordinates()[1],self.CreateCoordinates()[2])\n",
        "\n",
        "    def Reshape_(self,matrix_):\n",
        "        return matrix_.reshape(self.shapeReFactor)\n",
        "\n",
        "    def CreateLocalSpace(self):\n",
        "        return pd.DataFrame({'Recency': self.Reshape_(self.CreateGrids4Segment()[0]),\n",
        "                             'Frequency': self.Reshape_(self.CreateGrids4Segment()[1]),\n",
        "                             'Monetary': self.Reshape_(self.CreateGrids4Segment()[2]),\n",
        "                             'Label': [self._label]*self.shapeReFactor})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u8pnOOILA9H0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following class has the required values to create the theoretical cubic space with arbitrary boundaries.\n",
        "\n",
        "builderCubicSpace calls LocalSpace, and it creates the cubic space with these attributes. This is the part of the code that you can modify if you want to add/remove labels, or change the boundaries either by other percentiles, or by customized limits."
      ]
    },
    {
      "metadata": {
        "id": "-j7O1DVh16pi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RFMlabels():\n",
        "  \n",
        "# we require the dataset, and pre-defined labels for the automatic generation.\n",
        "# since we decide to use quintiles, we can predefine the limits in recency,\n",
        "# frequency and monetary for every label\n",
        "# from this limits we are able to build the customer abstract space\n",
        "  def __init__(self):\n",
        "    \n",
        "    self.labels= ['champions','loyal customers','potential loyalist','new customers',\n",
        "           'promising','need attention','about to sleep','at risk',\n",
        "           'cant lose them','hibernating','lost']\n",
        "    self.x = np.array([[0.0,0.2],\n",
        "                         [0.0,0.6],\n",
        "                         [0.0,0.4],\n",
        "                         [0.0,0.2],\n",
        "                         [0.2,0.4],\n",
        "                         [0.4,0.6],\n",
        "                         [0.4,0.6],\n",
        "                         [0.6,1.0],\n",
        "                         [0.8,1.0],\n",
        "                         [0.6,0.8],\n",
        "                         [0.6,1.0]])\n",
        "    self.y = np.array([[0.8,1.0],\n",
        "                           [0.6,1.0],\n",
        "                           [0.2,0.6],\n",
        "                           [0.0,0.2],\n",
        "                           [0.0,0.2],\n",
        "                           [0.4,0.6],\n",
        "                           [0.0,0.4],\n",
        "                           [0.4,1.0],\n",
        "                           [0.8,1.0],\n",
        "                           [0.2,0.4],\n",
        "                           [0.0,0.4]])\n",
        "    self.z = np.array([[0.8,1.0],\n",
        "                           [0.6,1.0],\n",
        "                           [0.2,0.6],\n",
        "                           [0.0,0.2],\n",
        "                           [0.0,0.2],\n",
        "                           [0.4,0.6],\n",
        "                           [0.0,0.4],\n",
        "                           [0.4,1.0],\n",
        "                           [0.8,1.0],\n",
        "                           [0.2,0.4],\n",
        "                           [0.0,0.4]])\n",
        "    \n",
        "    self.CubicSpace = pd.DataFrame({'Recency': [],\n",
        "                                'Frequency': [],\n",
        "                                'Monetary': [],\n",
        "                                'Label': []})\n",
        "\n",
        "  \n",
        "  def builderCubicSpace(self):\n",
        "    for i in range(len(self.labels)):\n",
        "      self.CubicSpace= self.CubicSpace.append(LocalSpace(self.labels[i],20,self.x[i],self.y[i],self.z[i]).CreateLocalSpace())\n",
        "    return self.CubicSpace\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NVAzjuBYGd1Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training the classificator\n",
        "Once you have created the training set, with the well delimited boundaries, the only thing you need to do is to train a model.\n",
        "\n",
        "Practically, the automata is going to learn from the boundaries and assign the corresponding label. For this case, and for simplicity, we are going to train a decission tree with some arbitrary hyperparameters. You are free to train the model that you want, even to run a grid search algorithm."
      ]
    },
    {
      "metadata": {
        "id": "vs1EPut9HA3-",
        "colab_type": "code",
        "outputId": "756d177e-639f-4ad2-d320-7418c516ba25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1438
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import time\n",
        "\n",
        "df = RFMlabels().builderCubicSpace()\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(df[['Recency','Frequency','Monetary']], \n",
        "                                                                df[['Label']], test_size=0.25, random_state=42)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train,test_size=0.25,random_state=68)\n",
        "\n",
        "classifier_ = DecisionTreeClassifier(criterion='entropy', max_depth= 10, min_samples_split= 3)\n",
        "\n",
        "classifier_.fit(X_train,y_train)\n",
        "\n",
        "y_true, y_pred = y_test, classifier_.predict(X_test)\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('**********************************************************')\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('**********************************************************')\n",
        "\n",
        "#Validation\n",
        "y_true, y_pred = y_validation, classifier_.predict(X_validation)\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('**********************************************************')\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('**********************************************************')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "    about to sleep       0.95      0.96      0.95      1492\n",
            "           at risk       1.00      0.91      0.95      1623\n",
            "    cant lose them       0.93      1.00      0.97      1451\n",
            "         champions       0.91      1.00      0.95      1541\n",
            "       hibernating       0.88      1.00      0.93      1439\n",
            "              lost       0.97      0.85      0.91      1521\n",
            "   loyal customers       0.98      0.90      0.94      1492\n",
            "    need attention       0.98      1.00      0.99      1494\n",
            "     new customers       0.98      0.96      0.97      1520\n",
            "potential loyalist       1.00      0.97      0.98      1471\n",
            "         promising       0.95      0.98      0.96      1456\n",
            "\n",
            "         micro avg       0.96      0.96      0.96     16500\n",
            "         macro avg       0.96      0.96      0.96     16500\n",
            "      weighted avg       0.96      0.96      0.96     16500\n",
            "\n",
            "**********************************************************\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "    about to sleep       0.95      0.96      0.95      1492\n",
            "           at risk       1.00      0.91      0.95      1623\n",
            "    cant lose them       0.93      1.00      0.97      1451\n",
            "         champions       0.91      1.00      0.95      1541\n",
            "       hibernating       0.88      1.00      0.93      1439\n",
            "              lost       0.97      0.85      0.91      1521\n",
            "   loyal customers       0.98      0.90      0.94      1492\n",
            "    need attention       0.98      1.00      0.99      1494\n",
            "     new customers       0.98      0.96      0.97      1520\n",
            "potential loyalist       1.00      0.97      0.98      1471\n",
            "         promising       0.95      0.98      0.96      1456\n",
            "\n",
            "         micro avg       0.96      0.96      0.96     16500\n",
            "         macro avg       0.96      0.96      0.96     16500\n",
            "      weighted avg       0.96      0.96      0.96     16500\n",
            "\n",
            "**********************************************************\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "    about to sleep       0.96      0.95      0.96      2039\n",
            "           at risk       0.99      0.91      0.95      1982\n",
            "    cant lose them       0.94      1.00      0.97      2078\n",
            "         champions       0.93      1.00      0.96      1962\n",
            "       hibernating       0.88      1.00      0.93      1970\n",
            "              lost       0.98      0.84      0.91      1949\n",
            "   loyal customers       0.98      0.92      0.95      1981\n",
            "    need attention       0.98      1.00      0.99      1981\n",
            "     new customers       0.97      0.96      0.97      1992\n",
            "potential loyalist       1.00      0.97      0.99      1975\n",
            "         promising       0.95      0.97      0.96      2091\n",
            "\n",
            "         micro avg       0.96      0.96      0.96     22000\n",
            "         macro avg       0.96      0.96      0.96     22000\n",
            "      weighted avg       0.96      0.96      0.96     22000\n",
            "\n",
            "**********************************************************\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "    about to sleep       0.96      0.95      0.96      2039\n",
            "           at risk       0.99      0.91      0.95      1982\n",
            "    cant lose them       0.94      1.00      0.97      2078\n",
            "         champions       0.93      1.00      0.96      1962\n",
            "       hibernating       0.88      1.00      0.93      1970\n",
            "              lost       0.98      0.84      0.91      1949\n",
            "   loyal customers       0.98      0.92      0.95      1981\n",
            "    need attention       0.98      1.00      0.99      1981\n",
            "     new customers       0.97      0.96      0.97      1992\n",
            "potential loyalist       1.00      0.97      0.99      1975\n",
            "         promising       0.95      0.97      0.96      2091\n",
            "\n",
            "         micro avg       0.96      0.96      0.96     22000\n",
            "         macro avg       0.96      0.96      0.96     22000\n",
            "      weighted avg       0.96      0.96      0.96     22000\n",
            "\n",
            "**********************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x_qeyH6IHqV1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Saving your local classificator.\n",
        "If you are on a local machine, you can save your classificator with the pickle library and run that model anytime you want. If you do this, you don't have to train the classificator for every run, and for every dataset, just load the saved model and that's it."
      ]
    },
    {
      "metadata": {
        "id": "aQj3Hkj2JOr1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = 'RFPredictor.sav'\n",
        "pickle.dump(classifier_1, open(filename, 'wb'))\n",
        " \n",
        "# some time later...\n",
        " \n",
        "# load the model from disk\n",
        "#loaded_model = pickle.load(open(filename, 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CF4vfEDMJeJO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This how the entire code looks like:"
      ]
    },
    {
      "metadata": {
        "id": "32UQNBu8Jg6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "outputId": "eabe52fc-11eb-44e4-d21a-f7b07d75b8ce"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class LocalSpace():\n",
        "  \n",
        "    def __init__(self,label,totalCostumers,x,y,z):\n",
        "        self._label=label\n",
        "        self._noCostumers = totalCostumers\n",
        "        self._x= x\n",
        "        self._y= y\n",
        "        self._z= z\n",
        "        self.shapeReFactor=totalCostumers*totalCostumers*totalCostumers\n",
        "\n",
        "    def CreateCoordinates(self):\n",
        "        x_ = np.linspace(self._x[0],self._x[1],self._noCostumers)\n",
        "        y_ = np.linspace(self._y[0],self._y[1],self._noCostumers)\n",
        "        z_ = np.linspace(self._z[0],self._z[1],self._noCostumers)\n",
        "        return(x_,y_,z_)\n",
        "\n",
        "    def CreateGrids4Segment(self):\n",
        "        return np.meshgrid(self.CreateCoordinates()[0],self.CreateCoordinates()[1],self.CreateCoordinates()[2])\n",
        "\n",
        "    def Reshape_(self,matrix_):\n",
        "        return matrix_.reshape(self.shapeReFactor)\n",
        "\n",
        "    def CreateLocalSpace(self):\n",
        "        return pd.DataFrame({'Recency': self.Reshape_(self.CreateGrids4Segment()[0]),\n",
        "                             'Frequency': self.Reshape_(self.CreateGrids4Segment()[1]),\n",
        "                             'Monetary': self.Reshape_(self.CreateGrids4Segment()[2]),\n",
        "                             'Label': [self._label]*self.shapeReFactor})\n",
        "      \n",
        "class RFMlabels():\n",
        "  \n",
        "# we require the dataset, and pre-defined labels for the automatic generation.\n",
        "# since we decide to use quintiles, we can predefine the limits in recency,\n",
        "# frequency and monetary for every label\n",
        "# from this limits we are able to build the customer abstract space\n",
        "  def __init__(self):\n",
        "    \n",
        "    self.labels= ['champions','loyal customers','potential loyalist','new customers',\n",
        "           'promising','need attention','about to sleep','at risk',\n",
        "           'cant lose them','hibernating','lost']\n",
        "    self.x = np.array([[0.0,0.2],\n",
        "                         [0.0,0.6],\n",
        "                         [0.0,0.4],\n",
        "                         [0.0,0.2],\n",
        "                         [0.2,0.4],\n",
        "                         [0.4,0.6],\n",
        "                         [0.4,0.6],\n",
        "                         [0.6,1.0],\n",
        "                         [0.8,1.0],\n",
        "                         [0.6,0.8],\n",
        "                         [0.6,1.0]])\n",
        "    self.y = np.array([[0.8,1.0],\n",
        "                           [0.6,1.0],\n",
        "                           [0.2,0.6],\n",
        "                           [0.0,0.2],\n",
        "                           [0.0,0.2],\n",
        "                           [0.4,0.6],\n",
        "                           [0.0,0.4],\n",
        "                           [0.4,1.0],\n",
        "                           [0.8,1.0],\n",
        "                           [0.2,0.4],\n",
        "                           [0.0,0.4]])\n",
        "    self.z = np.array([[0.8,1.0],\n",
        "                           [0.6,1.0],\n",
        "                           [0.2,0.6],\n",
        "                           [0.0,0.2],\n",
        "                           [0.0,0.2],\n",
        "                           [0.4,0.6],\n",
        "                           [0.0,0.4],\n",
        "                           [0.4,1.0],\n",
        "                           [0.8,1.0],\n",
        "                           [0.2,0.4],\n",
        "                           [0.0,0.4]])\n",
        "    \n",
        "    self.CubicSpace = pd.DataFrame({'Recency': [],\n",
        "                                'Frequency': [],\n",
        "                                'Monetary': [],\n",
        "                                'Label': []})\n",
        "\n",
        "  \n",
        "  def builderCubicSpace(self):\n",
        "    for i in range(len(self.labels)):\n",
        "      self.CubicSpace= self.CubicSpace.append(LocalSpace(self.labels[i],20,self.x[i],self.y[i],self.z[i]).CreateLocalSpace())\n",
        "    return self.CubicSpace\n",
        "\n",
        "#*************************************************************************************#  \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import time\n",
        "\n",
        "df = RFMlabels().builderCubicSpace()\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(df[['Recency','Frequency','Monetary']], \n",
        "                                                                df[['Label']], test_size=0.25, random_state=42)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train,test_size=0.25,random_state=68)\n",
        "\n",
        "classifier_ = DecisionTreeClassifier(criterion='entropy', max_depth= 10, min_samples_split= 3)\n",
        "\n",
        "classifier_.fit(X_train,y_train)\n",
        "\n",
        "y_true, y_pred = y_test, classifier_.predict(X_test)\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('**********************************************************')\n",
        "\n",
        "#Validation\n",
        "y_true, y_pred = y_validation, classifier_.predict(X_validation)\n",
        "print(classification_report(y_true, y_pred))\n",
        "print('**********************************************************')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "    about to sleep       0.95      0.96      0.95      1492\n",
            "           at risk       1.00      0.91      0.95      1623\n",
            "    cant lose them       0.93      1.00      0.97      1451\n",
            "         champions       0.91      1.00      0.95      1541\n",
            "       hibernating       0.88      1.00      0.93      1439\n",
            "              lost       0.97      0.85      0.91      1521\n",
            "   loyal customers       0.98      0.90      0.94      1492\n",
            "    need attention       0.98      1.00      0.99      1494\n",
            "     new customers       0.98      0.96      0.97      1520\n",
            "potential loyalist       1.00      0.97      0.98      1471\n",
            "         promising       0.95      0.98      0.96      1456\n",
            "\n",
            "         micro avg       0.96      0.96      0.96     16500\n",
            "         macro avg       0.96      0.96      0.96     16500\n",
            "      weighted avg       0.96      0.96      0.96     16500\n",
            "\n",
            "**********************************************************\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "    about to sleep       0.96      0.95      0.96      2039\n",
            "           at risk       0.99      0.91      0.95      1982\n",
            "    cant lose them       0.94      1.00      0.97      2078\n",
            "         champions       0.93      1.00      0.96      1962\n",
            "       hibernating       0.88      1.00      0.93      1970\n",
            "              lost       0.98      0.84      0.91      1949\n",
            "   loyal customers       0.98      0.92      0.95      1981\n",
            "    need attention       0.98      1.00      0.99      1981\n",
            "     new customers       0.97      0.96      0.97      1992\n",
            "potential loyalist       1.00      0.97      0.99      1975\n",
            "         promising       0.95      0.97      0.96      2091\n",
            "\n",
            "         micro avg       0.96      0.96      0.96     22000\n",
            "         macro avg       0.96      0.96      0.96     22000\n",
            "      weighted avg       0.96      0.96      0.96     22000\n",
            "\n",
            "**********************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yEN0iO6GJ2b0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you want to see this code in action, and a further explanation, don't forget to click [on this link]() to see it on kaggle. \n",
        "\n",
        "Or, if you want some explanation about the simplicity and foundations of an RFM analysis, you can read [this post on medium (spanish version\n",
        ")]().\n",
        "\n",
        "If you are an analyst, and want to use the results from an RFM analysis, and put together into a dashboard, you can visit [this link where the results from the kaggle implementation are depicted into a tableau dashboard]()"
      ]
    }
  ]
}